{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd976d2-ade8-4900-9b1f-5c912808e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f4759-1337-459b-8e14-7a6e7978b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Reshape (28x28 images to 784 length vectors\n",
    "x_train_flat = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_flat = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# channel dimension\n",
    "x_train_conv = np.expand_dims(x_train, axis=1)\n",
    "x_test_conv = np.expand_dims(x_test, axis=1)\n",
    "\n",
    "print(f\"Flattened shape: {x_train_flat.shape}\")\n",
    "print(f\"Convolutional train shape: {x_train_conv.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67123dc0-8237-4e5b-a7cc-83b4bdc04221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected autoencoder\n",
    "\n",
    "# Input size for MINST images\n",
    "input_size = 784\n",
    "\n",
    "# Desired size of the encoded representation\n",
    "encoding_dim = 32\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(input_size,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoder_output = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation='relu')(encoder_output)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(input_size, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compile autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Create seperate encoder model...extract latent representation\n",
    "encoder = Model(input_img, encoder_output)\n",
    "\n",
    "print(\"Simple fully-connected autoencoder architecture\")\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14112e81-6eca-434c-8c54-5e9c9c318223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fully-connected autoencoder\n",
    "\n",
    "autoencoder.fit(x_train_flat, x_train_flat,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_flat, x_test_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a35e83-9a67-4410-a3ae-11656c86f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoded (latent) representations from the test set\n",
    "encoded_imgs = encoder.predict(x_test_flat) # For flattened autoencoder\n",
    "# encoded_imgs_conv = encoder_conv.predict(x_test_conv) # For convolutional autoencoder\n",
    "\n",
    "print(f\"\\nShape of encoded images (latent space): {encoded_imgs.shape}\")\n",
    "\n",
    "# You can also get reconstructed images to visualize how well it learned\n",
    "decoded_imgs = autoencoder.predict(x_test_flat)\n",
    "\n",
    "# Visualize original vs. reconstructed images\n",
    "n = 10 # Number of digits to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28)) # Use original x_test for display\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle(\"Original vs. Reconstructed MNIST Digits\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e618a243-c0c2-4e24-892e-a7414b52953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return given digit utilizing MNIST 'handwriting'\n",
    "\n",
    "# --- Modified Helper Function to Get a Single Reconstructed Digit Image ---\n",
    "def get_reconstructed_mnist_digit_image(\n",
    "    digit_to_recreate, autoencoder_model, x_test_flat, test_labels_array\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a 28x28 reconstructed image array of a specified MNIST digit.\n",
    "\n",
    "    Args:\n",
    "        digit_to_recreate (int): The digit (0-9) to recreate.\n",
    "        autoencoder_model (tf.keras.Model): The trained fully connected autoencoder model.\n",
    "        x_test_flat (np.array): The preprocessed (flattened and normalized) MNIST test data.\n",
    "        test_labels_array (np.array): The labels for the MNIST test data.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A 28x28 numpy array representing the reconstructed digit image,\n",
    "                  or None if the digit is out of range or not found.\n",
    "    \"\"\"\n",
    "    if not 0 <= digit_to_recreate <= 9:\n",
    "        print(f\"Warning: Digit '{digit_to_recreate}' is not a valid MNIST digit (0-9). Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # Find indices of the desired digit in the test set\n",
    "    indices = np.where(test_labels_array == digit_to_recreate)[0]\n",
    "\n",
    "    if len(indices) == 0:\n",
    "        print(f\"Warning: No examples of digit {digit_to_recreate} found in the test set. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # Take the first example of that digit for reconstruction\n",
    "    original_image_flat = x_test_flat[indices[0]:indices[0]+1] # Keep batch dimension\n",
    "\n",
    "    # Predict the reconstructed image\n",
    "    reconstructed_image_flat = autoencoder_model.predict(original_image_flat, verbose=0)\n",
    "\n",
    "    # Reshape to 28x28 for consistent output\n",
    "    reconstructed_image_reshaped = reconstructed_image_flat.reshape(28, 28)\n",
    "\n",
    "    return reconstructed_image_reshaped\n",
    "\n",
    "# --- New Function to Recreate Multi-Digit Numbers ---\n",
    "def recreate_multi_digit_number(number, autoencoder_model, x_test_flat, y_test):\n",
    "    \"\"\"\n",
    "    Recreates a multi-digit number by combining reconstructed MNIST digits.\n",
    "\n",
    "    Args:\n",
    "        number (int or str): The number to recreate (e.g., 100, \"543\").\n",
    "        autoencoder_model (tf.keras.Model): The trained fully connected autoencoder model.\n",
    "        x_test_flat (np.array): The preprocessed (flattened and normalized) MNIST test data.\n",
    "        y_test (np.array): The labels for the MNIST test data.\n",
    "    \"\"\"\n",
    "    number_str = str(number)\n",
    "    digit_images = []\n",
    "\n",
    "    print(f\"Attempting to recreate number: {number_str}\")\n",
    "\n",
    "    for char_digit in number_str:\n",
    "        try:\n",
    "            digit = int(char_digit)\n",
    "            reconstructed_img = get_reconstructed_mnist_digit_image(\n",
    "                digit, autoencoder_model, x_test_flat, y_test\n",
    "            )\n",
    "            if reconstructed_img is not None:\n",
    "                digit_images.append(reconstructed_img)\n",
    "            else:\n",
    "                print(f\"Could not reconstruct digit '{char_digit}'. Result will be incomplete.\")\n",
    "        except ValueError:\n",
    "            print(f\"Warning: '{char_digit}' is not a valid digit. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    if not digit_images:\n",
    "        print(\"Could not recreate any digits for the given number.\")\n",
    "        return\n",
    "\n",
    "    # Horizontally stack the reconstructed digit images\n",
    "    combined_image = np.hstack(digit_images)\n",
    "\n",
    "    plt.figure(figsize=(len(digit_images) * 2, 3)) # Adjust figure size based on number of digits\n",
    "    plt.imshow(combined_image, cmap='gray')\n",
    "    plt.title(f\"Reconstructed Number: {number_str}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb02d904-edfb-4599-8f47-243374e93b0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recreate_multi_digit_number(\u001b[38;5;241m100\u001b[39m, autoencoder, x_test_flat, y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "recreate_multi_digit_number(100, autoencoder, x_test_flat, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe77119-aca7-4ff7-a86c-faf83fce2d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
